# Data Mining and Machine Learning (61761) ü§ñüìä

**Institution:** Braude College of Engineering  
**Department:** Software Engineering and Information Systems  
**Semester:** A - 2026  
**Language:** Python  

## üìå Overview
This repository documents the laboratory exercises and practical implementations for the **Data Mining and Machine Learning (61761)** course. The course deals with advanced principles of data mining, covering supervised and unsupervised learning, dimensionality reduction, and deep learning.

The objective of these labs is to conceive and implement basic machine learning approaches in real-world applications using Python.

## üöÄ Key Learning Outcomes
This course provided a comprehensive bridge between theoretical statistical modeling and practical software engineering. By completing these labs, I gained:

* **End-to-End Pipeline Mastery:** The ability to take raw data, clean and preprocess it, select the appropriate model, and evaluate its performance.
* **Algorithm Intuition:** A deep understanding of *when* to use specific algorithms (e.g., SVM vs. Random Forest) based on data characteristics.
* **Deep Learning Proficiency:** Practical experience building, training, and debugging complex neural network architectures (CNNs, RNNs) using TensorFlow and Keras.
* **Model Optimization:** Skills in hyperparameter tuning (Grid Search), regularization (Lasso/Ridge), and preventing overfitting (Dropout).

## üìÇ Lab Breakdown
Each lab focuses on a specific aspect of the ML pipeline, progressing from classical methods to deep learning.

### Phase 1: Classical Machine Learning
* **Lab 02: Data Cleaning & EDA**
    * *Focus:* Data preprocessing on the **Titanic Dataset**.
    * *Skills:* Missing value imputation, outlier detection, and correlation analysis (Heatmaps).
* **Lab 03: Classification Algorithms**
    * *Focus:* Supervised classification on the **Iris Dataset**.
    * *Skills:* Implementing and comparing K-Nearest Neighbors (KNN), Decision Trees, and Naive Bayes.
* **Lab 04: Regression & Regularization**
    * *Focus:* Predicting continuous variables using the **Boston Housing Dataset**.
    * *Skills:* Linear & Polynomial Regression, utilizing Ridge and Lasso regularization to reduce variance.
* **Lab 05: Unsupervised Learning**
    * *Focus:* Grouping unlabeled data and dimensionality reduction.
    * *Skills:* K-Means Clustering, Hierarchical Clustering (Dendrograms), and PCA.
* **Lab 06: Support Vector Machines (SVM)**
    * *Focus:* Linear and non-linear classification on the **Digits Dataset**.
    * *Skills:* Optimizing Kernel functions (RBF, Poly) and hyperparameter tuning.

### Phase 2: Neural Networks & Deep Learning
* **Lab 08: Neural Networks Fundamentals**
    * *Focus:* Building Multi-Layer Perceptrons (MLP) for **MNIST**.
    * *Skills:* Forward/Backward propagation, Dense layers, and activation functions (ReLU, Softmax).
* **Lab 09: Convolutional Neural Networks (CNN)**
    * *Focus:* Image classification.
    * *Skills:* Engineering architectures with Convolutional (`Conv2D`) and Max Pooling layers.
* **Lab 10: Transfer Learning**
    * *Focus:* Leveraging pre-trained models for small datasets.
    * *Skills:* Fine-tuning **VGG16/ResNet** architectures for custom image recognition tasks.
* **Lab 11: RNN & Natural Language Processing**
    * *Focus:* Sentiment Analysis on **IMDB Movie Reviews**.
    * *Skills:* Sequence modeling using LSTM/GRU layers and text tokenization.

## üõ†Ô∏è Tech Stack
* **Language:** Python
* **Libraries:**
    * `scikit-learn` (Classical ML algorithms)
    * `TensorFlow` / `Keras` (Deep Learning)
    * `NumPy` & `Pandas` (Data manipulation)
    * `Matplotlib` / `Seaborn` (Visualization)

## üìñ Course References
Based on the syllabus literature:
* *Deep Learning* - Goodfellow, Bengio, Courville
* *Dive into Deep Learning* - Zhang, Lipton, Li, Smola
* *Introduction to Machine Learning with Python* - M√ºller & Guido

---
*Disclaimer: This repository is for educational purposes and documents my work during the course.*
