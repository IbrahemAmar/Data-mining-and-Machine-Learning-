{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IbrahemAmar/Data-mining-and-Machine-Learning-/blob/main/lab11_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "import random\n",
        "\n",
        "IMG_SIZE = 28"
      ],
      "metadata": {
        "id": "m2nv4zYXH4Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotSamples(data,rows,cols,names,tLabels,pLabels=[]):\n",
        "    fig, axs = plt.subplots(rows,cols)\n",
        "    nDigits = data.shape[0]\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            index = random.randint(0,nDigits-1)\n",
        "            axs[i,j].imshow(data[index],cmap = 'gray')\n",
        "            # remove axes titles\n",
        "            axs[i,j].axis('off')\n",
        "            if (np.any(pLabels)):\n",
        "                axs[i,j].set_title('P: %s, T: %s' % (names[pLabels[index]], names[tLabels[index]]) ,fontdict={'fontsize': 10})\n",
        "            else:\n",
        "                axs[i,j].set_title('T: %s' % names[tLabels[index]],fontdict={'fontsize': 10})\n",
        "            # show the figure\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1J3ivyL7H4LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D())\n",
        "\n",
        "  #NEW layer\n",
        "\tmodel.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D())\n",
        "\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(64, activation='relu'))\n",
        "\tmodel.add(Dense(nClasses, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "KU8y_iFJH4JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotTrainingCurves(history,numEpochs):\n",
        "  #Process ploting\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.axis([0,numEpochs,0,1])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Accuracy','loss','val_accuracy','val_loss'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "PJ4mug65H4Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view original images with an augmented image\n",
        "def visualize(original, augmented, title=\"\"):\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title('Original image')\n",
        "  plt.imshow(original,cmap = 'gray')\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title(title + \" image\")\n",
        "  plt.imshow(augmented,cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5oHvF4hZH4EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image augmentation tensor model\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),  # ±18°\n",
        "    tf.keras.layers.RandomZoom(0.2),  # Random zoom in/out\n",
        "    tf.keras.layers.RandomTranslation(0.2, 0.2),  # Random shift (10% height & width)\n",
        "    # tf.keras.layers.RandomFlip(\"vertical\"), ## NEW flip vertical\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "MuKIF66wIDQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply it in map() — runs on GPU if model runs on GPU\n",
        "def augment(image,label):\n",
        "    image = data_augmentation(image, training=True)  # important: training=True\n",
        "    return image,label"
      ],
      "metadata": {
        "id": "8Y-S-o0jIDKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = [\"0\", \"1\", \"2\", \"3\", \"4\",\"5\", \"6\", \"7\", \"8\", \"9\"]"
      ],
      "metadata": {
        "id": "3nCiDHVmIGUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainData.shape, trainLabels.shape))\n",
        "print('Test: X=%s, y=%s' % (testData.shape, testLabels.shape))"
      ],
      "metadata": {
        "id": "9O2YRwA-IGIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 3\n",
        "cols = 3\n",
        "\n",
        "plotSamples(trainData,rows,cols,names,trainLabels)"
      ],
      "metadata": {
        "id": "PS5izuRTIKfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image data augmentations\n",
        "\n",
        "for i in range(3):\n",
        "    index = index = random.randint(0,trainData.shape[0])\n",
        "    image = trainData[index].reshape(28,28,1)\n",
        "\n",
        "    # random flip\n",
        "    randomFlip = tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "    flippedImage = randomFlip(image)\n",
        "    visualize(image,flippedImage,\"Random Flip\")\n",
        "\n",
        "    # ±18° rotation\n",
        "    randomRotation = tf.keras.layers.RandomRotation(0.1)\n",
        "    rotatedImage = randomRotation(image)\n",
        "    visualize(image,rotatedImage,\"Random Rotation\")\n",
        "\n",
        "    # Random zoom in/out\n",
        "    randomZoom = tf.keras.layers.RandomZoom(0.2)\n",
        "    zoomedImage = randomZoom(image)\n",
        "    visualize(image,zoomedImage,\"Random Zoom\")\n",
        "\n",
        "    # Random shift (20% height & width)\n",
        "    randomTranslation = tf.keras.layers.RandomTranslation(0.2, 0.2)\n",
        "    translatedImage = randomTranslation(image)\n",
        "    visualize(image, translatedImage,\"Random Translation\")\n",
        "\n",
        "    #data augmentation\n",
        "    augmentedImage = data_augmentation(image)\n",
        "    visualize(image, augmentedImage,\"augmented\")"
      ],
      "metadata": {
        "id": "GcsIh9uxIKUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = trainData.reshape((trainData.shape[0], 28, 28, 1)).astype('float32')\n",
        "testData = testData.reshape((testData.shape[0], 28, 28, 1)).astype('float32')\n",
        "\n",
        "catTrainLabels = to_categorical(trainLabels,num_classes=10)\n",
        "catTestLabels = to_categorical(testLabels,num_classes=10)\n",
        "trainData = trainData/255.0\n",
        "testData = testData/255.0"
      ],
      "metadata": {
        "id": "CB4RexjHIO10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "# generate a tensor train flow data set\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((trainData, catTrainLabels))\n",
        "    .shuffle(10000)\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .cache()\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "pKOFQDOOIOzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a tensor test flow data set\n",
        "test_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((testData, catTestLabels))\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .cache()\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "lMz6SFgbIOwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create NON-AUGMENTED training pipeline\n",
        "train_ds_no_aug = (\n",
        "    tf.data.Dataset.from_tensor_slices((trainData, catTrainLabels))\n",
        "    .shuffle(10000)\n",
        "    .cache()\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Create NON-AUGMENTED testing pipeline\n",
        "test_ds_no_aug = (\n",
        "    tf.data.Dataset.from_tensor_slices((testData, catTestLabels))\n",
        "    .cache()\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Aqylh8kzJndP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nClasses = catTestLabels.shape[1]\n",
        "# train the model\n",
        "model = baseline_model()\n",
        "model_no_aug = baseline_model()\n",
        "\n",
        "nEpochs = 15"
      ],
      "metadata": {
        "id": "nieYcbHGIU1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor the validation loss\n",
        "    patience=2,          # Stop if no improvement for 2 epochs\n",
        "    verbose=1,           # Print a message when stopping\n",
        "    mode='min',          # Stop when the loss is no longer decreasing\n",
        "    restore_best_weights=True # Restore the best weights found\n",
        ")"
      ],
      "metadata": {
        "id": "KeQrveH3IUyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, validation_data=test_ds, epochs=nEpochs,callbacks=[early_stopping])\n",
        "\n",
        "history_no_aug = model_no_aug.fit(\n",
        "train_ds_no_aug,\n",
        "    validation_data=test_ds_no_aug,\n",
        "    epochs=nEpochs,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "AK-OemHdIZKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotTrainingCurves(history,nEpochs)"
      ],
      "metadata": {
        "id": "uhlf1y0zIbHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted the test data\n",
        "predLabels = model.predict(testData).argmax(1)"
      ],
      "metadata": {
        "id": "0ZiNckjoIdNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unpack tensor to augmented test numpy arry\n",
        "augmentedTestData = tf.concat([x for x, y in test_ds], axis=0).numpy()"
      ],
      "metadata": {
        "id": "JyOEmIG8IgFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hik9YjZGH1Vi"
      },
      "outputs": [],
      "source": [
        "plotSamples(augmentedTestData,rows,cols,names,testLabels,predLabels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define models to evaluate\n",
        "models_to_test = [(\"Augmented\", model), (\"Non-Augmented\", model_no_aug)]\n",
        "\n",
        "for name, m in models_to_test:\n",
        "    # 1. Predict and Matrix\n",
        "    preds = m.predict(testData, verbose=0).argmax(axis=1)\n",
        "    cm = confusion_matrix(testLabels, preds)\n",
        "\n",
        "    # 2. Plot\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues' if name == \"Augmented\" else 'Oranges')\n",
        "    plt.title(f'Confusion Matrix: {name}')\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Print Error Rate (Formatted strictly as Digit: Rate)\n",
        "    # Calculate error rate per digit (1 - accuracy)\n",
        "    error_rates = 1 - (cm.diagonal() / cm.sum(axis=1))\n",
        "\n",
        "    print(f\"\\n>>> {name} Error Rates:\")\n",
        "    for digit, rate in enumerate(error_rates):\n",
        "        print(f\"{digit}: {rate:.2%}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "ME_GzaoMIAkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Pick a random image from the training set\n",
        "index = random.randint(0, trainData.shape[0])\n",
        "original_image = trainData[index]\n",
        "\n",
        "# 2. Define a Vertical Flip layer specifically for visualization\n",
        "vertical_flip_layer = tf.keras.layers.RandomFlip(\"vertical\")\n",
        "\n",
        "# 3. Apply the flip (we need to add a batch dimension first, then remove it)\n",
        "# The seed ensures we get a flip for visualization purposes\n",
        "flipped_image = vertical_flip_layer(tf.expand_dims(original_image, 0), training=True)\n",
        "flipped_image = tf.squeeze(flipped_image) # Remove the batch dimension\n",
        "\n",
        "# 4. Use your existing visualize function to plot them side-by-side\n",
        "# We use .squeeze() on the original to ensure dimensions match for plotting\n",
        "visualize(original_image.squeeze(), flipped_image, \"Vertically Flipped\")"
      ],
      "metadata": {
        "id": "BDdYzGu_SaYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Configuration: Define the specific augmentations we want\n",
        "# Storing them in a dictionary makes the code cleaner and look different\n",
        "aug_layers = {\n",
        "    \"Flipped\": tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    \"Zoomed\": tf.keras.layers.RandomZoom(height_factor=0.2),\n",
        "    \"Translated\": tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
        "}\n",
        "\n",
        "# 2. Get images\n",
        "my_images = [f for f in os.listdir() if f.endswith('.png') or f.endswith('.jpg')]\n",
        "my_images.sort()\n",
        "\n",
        "# 3. Process and Plot\n",
        "# We will create one row per image, with columns for the augmentations\n",
        "plt.figure(figsize=(12, 3 * len(my_images)))\n",
        "\n",
        "for i, filename in enumerate(my_images):\n",
        "    if i >= 4: break # Limit to first 4 images to keep plot readable\n",
        "\n",
        "    # --- Step A: Load with OpenCV (Alternative to PIL) ---\n",
        "    raw_img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "    raw_img = cv2.resize(raw_img, (28, 28))\n",
        "\n",
        "    # Invert and Normalize (Standard Paint -> MNIST prep)\n",
        "    # This replaces the \"1.0 - image\" logic with standard numpy math\n",
        "    clean_img = (255 - raw_img).astype('float32') / 255.0\n",
        "    input_tensor = clean_img.reshape(1, 28, 28, 1)\n",
        "\n",
        "    # --- Step B: Plot Original ---\n",
        "    # Calculate subplot index: (Row * 4 columns) + 1\n",
        "    plt.subplot(len(my_images), 4, (i * 4) + 1)\n",
        "    plt.imshow(clean_img, cmap='gray')\n",
        "    plt.title(f\"{filename}\\n(Original)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # --- Step C: Apply Augmentations Loop ---\n",
        "    col_index = 2\n",
        "    for aug_name, layer in aug_layers.items():\n",
        "        # Apply transformation (training=True is required for random layers)\n",
        "        transformed_tensor = layer(input_tensor, training=True)\n",
        "\n",
        "        # Convert back to numpy for plotting\n",
        "        result_img = transformed_tensor[0].numpy()\n",
        "\n",
        "        plt.subplot(len(my_images), 4, (i * 4) + col_index)\n",
        "        plt.imshow(result_img, cmap='gray')\n",
        "        plt.title(aug_name)\n",
        "        plt.axis('off')\n",
        "        col_index += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iVb533dZbAYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get list of images\n",
        "image_files = [f for f in os.listdir() if f.endswith('.png') or f.endswith('.jpg')]\n",
        "image_files.sort()\n",
        "image_files = image_files[:12] # Limit to 12\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "for i, filename in enumerate(image_files):\n",
        "    # --- Preprocessing ---\n",
        "    img_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "    img_resized = cv2.resize(img_gray, (28, 28))\n",
        "\n",
        "    # Invert and Normalize\n",
        "    img_inverted = 255 - img_resized\n",
        "    img_final = img_inverted.astype('float32') / 255.0\n",
        "    input_tensor = img_final.reshape(1, 28, 28, 1)\n",
        "\n",
        "    # --- Prediction 1: Non-Augmented Model ---\n",
        "    pred_no_aug = model_no_aug.predict(input_tensor, verbose=0)\n",
        "    label_no_aug = pred_no_aug.argmax()\n",
        "\n",
        "    # --- Prediction 2: Augmented Model ---\n",
        "    pred_aug = model.predict(input_tensor, verbose=0)\n",
        "    label_aug = pred_aug.argmax()\n",
        "\n",
        "    # --- Plotting ---\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(img_inverted, cmap='gray')\n",
        "\n",
        "    # Color logic: Green if they agree, Red if they disagree\n",
        "    title_color = 'black'\n",
        "    if label_no_aug == label_aug:\n",
        "        title_text = f\"Both agree: {label_no_aug}\"\n",
        "        title_color = 'green'\n",
        "    else:\n",
        "        title_text = f\"Non-Aug: {label_no_aug} | Aug: {label_aug}\"\n",
        "        title_color = 'red'\n",
        "\n",
        "    # REMOVED the confidence line here\n",
        "    plt.title(f\"{filename}\\n{title_text}\", color=title_color, fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_2xD9D2dZ7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}