{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IbrahemAmar/Data-mining-and-Machine-Learning-/blob/main/lab3_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import regular expressins packge\n",
        "# import numbers package\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "JZ-BUBW7n6xa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read file\n",
        "def readFile(fileName):\n",
        "    file = open(fileName,'r',encoding=\"cp437\")\n",
        "    fileText = \"\"\n",
        "    for line in file:\n",
        "        fileText += line\n",
        "    return fileText"
      ],
      "metadata": {
        "id": "gWMpvhX6n6uu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess text\n",
        "def preProcess(text):\n",
        "    # Remove non-letter chars\n",
        "    text = re.sub(\"[^a-zA-Z ]\",\" \", text)\n",
        "    # Change characters to lower\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "r-RU0VXCn6sB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genReferenceWordList(texts,stopWords):\n",
        "# concatenate the texts\n",
        "    allText = \"\"\n",
        "    for line in texts:\n",
        "        allText += line\n",
        "    # Generate a word list\n",
        "    wordsList =  allText.split()\n",
        "    # Generate a word set\n",
        "    wordsSet =  set(wordsList)\n",
        "    # Remove the stop words from the word list\n",
        "    stopWordsList = stopWords.split()\n",
        "    stopWordsSet = set(stopWordsList)\n",
        "    refWordSet = wordsSet.difference(stopWordsSet)\n",
        "    return list(refWordSet)"
      ],
      "metadata": {
        "id": "Z4jTb5lMn6pc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vector distance\n",
        "# find the distance between arrays\n",
        "def vecDist(vec1,vec2):\n",
        "    vecDiff = vec1-vec2\n",
        "    # compute the distance (\"pitagoras\")\n",
        "    vecSqr =  np.square(vecDiff)\n",
        "    vecSum =  np.sum(vecSqr)\n",
        "    return np.sqrt(vecSum)"
      ],
      "metadata": {
        "id": "QPAcaH7qn6mw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word frequency\n",
        "def getWordFrequency(texts,dictList):\n",
        "    dictSize = len(dictList)\n",
        "    nTexts = len(texts)\n",
        "    wordFreq = np.empty((nTexts,dictSize))\n",
        "    for i in range(nTexts):\n",
        "        print(\"text\" + str(i))\n",
        "        for j in range(dictSize):\n",
        "            wordFreq[i,j] = texts[i].count(dictList[j])\n",
        "    return wordFreq"
      ],
      "metadata": {
        "id": "7a56UQcNoQ-q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books = []\n",
        "#read  and preprocess files\n",
        "books+= [readFile('DB.txt')]\n",
        "books+= [readFile('Eliot.txt')]\n",
        "books+= [readFile('HP.txt')]"
      ],
      "metadata": {
        "id": "-Dm1gm3OoQ8F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window = 200000"
      ],
      "metadata": {
        "id": "AGuA1zpvoQ5Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split every book into two parts\n",
        "bookParts = []\n",
        "for book in books:\n",
        "    nParts = len(book)//window\n",
        "    for i in range(nParts):\n",
        "        bookParts += [book[i*window:(i+1)*window]]"
      ],
      "metadata": {
        "id": "t9SSIjAloU7G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess texts in book parts\n",
        "texts = []\n",
        "for text in bookParts:\n",
        "    texts += [preProcess(text)]"
      ],
      "metadata": {
        "id": "P2Fqrop4oUyi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read stop words file - words that can be removed\n",
        "stopWords = readFile('stopwords_en.txt')"
      ],
      "metadata": {
        "id": "Mupvf2ujoYLz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate reference word list\n",
        "refList = genReferenceWordList(texts,stopWords)"
      ],
      "metadata": {
        "id": "9SrXG7gRoYDe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the frequency of the reference words in the files\n",
        "wordFreq = getWordFrequency(texts,refList)"
      ],
      "metadata": {
        "id": "jWIATzKhobfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bee1b7-57ef-489d-fd30-f30d42f5915b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text0\n",
            "text1\n",
            "text2\n",
            "text3\n",
            "text4\n",
            "text5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-OBJg5O_n3gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdaac85d-ff1f-451b-efc2-f41e2eb90bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dist matrix = \n",
            " [[   0.  996. 2287. 2129. 2402. 2193.]\n",
            " [ 996.    0. 2154. 1990. 2316. 2079.]\n",
            " [2287. 2154.    0.  838. 2223. 2098.]\n",
            " [2129. 1990.  838.    0. 2005. 1914.]\n",
            " [2402. 2316. 2223. 2005.    0.  870.]\n",
            " [2193. 2079. 2098. 1914.  870.    0.]]\n"
          ]
        }
      ],
      "source": [
        "# find the distance matrix between the text files\n",
        "# text distances\n",
        "rows,colomns = wordFreq.shape\n",
        "\n",
        "dist = np.zeros((rows,rows))\n",
        "for i in range(rows):\n",
        "    for j in range(rows):\n",
        "        # calculate the distance between the frequency vectors\n",
        "        dist[i,j] = round(vecDist(wordFreq[i],wordFreq[j]))\n",
        "\n",
        "print(\"dist matrix = \\n\",dist)"
      ]
    }
  ]
}